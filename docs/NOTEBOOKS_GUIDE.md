# Gu√≠a de Notebooks para Proyecto de Predicci√≥n de Calidad del Caf√©

Esta gu√≠a describe el prop√≥sito, contenido y entregables de cada notebook en el proyecto.

---

## üìä 01_exploratory_data_analysis.ipynb

### Objetivo
Explorar y entender profundamente el dataset de calidad del caf√© del CQI antes de cualquier transformaci√≥n.

### Tareas Principales

#### 1. Configuraci√≥n Inicial
- Importar librer√≠as necesarias (pandas, numpy, matplotlib, seaborn, missingno)
- Configurar opciones de visualizaci√≥n y estilo de gr√°ficos
- Establecer semilla aleatoria para reproducibilidad

#### 2. Carga e Inspecci√≥n de Datos
- Cargar datasets de Arabica y Robusta desde `data/raw/`
- Mostrar informaci√≥n b√°sica: dimensiones, tipos de datos, primeras/√∫ltimas filas
- Listar todas las columnas y clasificarlas por tipo (num√©ricas, categ√≥ricas, target)

#### 3. An√°lisis de Calidad de Datos
- **Valores Faltantes:**
  - Calcular porcentaje de missing values por variable
  - Crear visualizaci√≥n con missingno (matriz y heatmap)
  - Identificar patrones de valores faltantes (MCAR, MAR, MNAR)
  - Clasificar variables: eliminar (>70% missing), imputar (<20%), analizar (20-70%)
- **Duplicados:**
  - Verificar registros duplicados completos
  - Mostrar ejemplos si existen
- **Consistencia:**
  - Verificar rangos v√°lidos (variables sensoriales 0-10, Total Cup Score 0-100)
  - Identificar valores fuera de rango esperado

#### 4. An√°lisis Univariado

**Variables Num√©ricas:**
- Calcular estad√≠sticas descriptivas completas (media, mediana, std, min, max, cuartiles)
- Calcular skewness y kurtosis para cada variable
- Interpretar distribuciones (sim√©trica, sesgada, colas pesadas)
- Crear histogramas + KDE para variables sensoriales
- Crear boxplots para detectar outliers
- An√°lisis detallado de variable objetivo (Total Cup Score):
  - Distribuci√≥n completa con m√∫ltiples visualizaciones
  - Clasificaci√≥n por categor√≠as CQI (Exceptional ‚â•90, Excellent 85-89, Very Good 80-84)
  - Q-Q plot para test de normalidad
  - Funci√≥n de distribuci√≥n acumulada

**Variables Categ√≥ricas:**
- Calcular n√∫mero de valores √∫nicos
- Mostrar top categor√≠as m√°s frecuentes
- Crear gr√°ficos de barras horizontales para top 10-15 categor√≠as
- Analizar: Country of Origin, Processing Method, Variety, Region

#### 5. An√°lisis de Outliers
- Detectar outliers usando m√©todo IQR (rango intercuart√≠lico)
- Detectar outliers usando Z-score (threshold=3)
- Calcular porcentaje de outliers por variable
- Crear tabla resumen de outliers
- Visualizar cantidad y porcentaje de outliers
- **Decisi√≥n preliminar:** Documentar qu√© hacer con outliers (mantener, transformar, eliminar)

#### 6. Conclusiones del EDA
- Resumen ejecutivo de hallazgos principales
- Insights clave sobre la calidad del caf√©
- Decisiones documentadas para preprocesamiento
- Variables candidatas a eliminar
- Estrategias de imputaci√≥n recomendadas

### Entregables
- Notebook completo con an√°lisis y visualizaciones
- Archivo `reports/EDA_Summary_Report.txt` con conclusiones
- ~10-15 visualizaciones guardadas en `reports/figures/eda/`

---

## üßπ 02_data_preprocessing.ipynb

### Objetivo
Limpiar y preparar los datos aplicando las decisiones tomadas durante el EDA.

### Tareas Principales

#### 1. Carga de Datos
- Cargar dataset original desde `data/raw/`
- Verificar integridad de los datos

#### 2. Limpieza de Datos

**Valores Faltantes:**
- Implementar estrategia de imputaci√≥n seg√∫n tipo de variable:
  - Variables num√©ricas: mediana (robusto ante outliers)
  - Variables categ√≥ricas: moda (valor m√°s frecuente)
  - Documentar cada decisi√≥n con justificaci√≥n
- Eliminar variables con >70% missing values
- Crear indicadores de imputaci√≥n si es necesario (flag columns)

**Duplicados:**
- Eliminar registros duplicados completos
- Documentar cu√°ntos se eliminaron

**Inconsistencias:**
- Corregir formatos de texto (min√∫sculas, eliminar espacios)
- Estandarizar nombres de categor√≠as (ej: "Washed" vs "washed" vs "WASHED")
- Convertir tipos de datos seg√∫n corresponda

#### 3. Tratamiento de Outliers
- Aplicar decisi√≥n tomada en EDA para cada variable:
  - Mantener: documentar justificaci√≥n (casos extremos leg√≠timos)
  - Transformar: aplicar log, sqrt, o winsorizing
  - Eliminar: solo si son errores claros de datos
- Registrar cu√°ntos outliers se trataron

#### 4. Eliminaci√≥n de Variables Irrelevantes
- Eliminar columnas identificadas en EDA:
  - Variables con >70% missing
  - Variables con varianza cero
  - Variables ID o redundantes
- Documentar raz√≥n de eliminaci√≥n

#### 5. Verificaci√≥n de Datos Limpios
- Verificar que no quedan valores faltantes (excepto estrat√©gicos)
- Verificar rangos de variables
- Calcular nuevas estad√≠sticas descriptivas
- Comparar antes vs despu√©s de limpieza

#### 6. Guardar Dataset Limpio
- Guardar en `data/processed/coffee_cleaned.csv`
- Guardar versiones separadas si es necesario (arabica_cleaned, robusta_cleaned)
- Crear diccionario de datos actualizado

### Entregables
- Dataset limpio: `data/processed/coffee_cleaned.csv`
- Resumen de transformaciones aplicadas
- Comparaci√≥n antes/despu√©s de limpieza

---

## üîß 03_feature_engineering.ipynb

### Objetivo
Crear nuevas caracter√≠sticas, codificar variables categ√≥ricas y preparar datos para modelado.

### Tareas Principales

#### 1. Carga de Datos Limpios
- Cargar `data/processed/coffee_cleaned.csv`
- Verificar integridad

#### 2. Codificaci√≥n de Variables Categ√≥ricas

**One-Hot Encoding:**
- Aplicar a variables con <20 categor√≠as √∫nicas
- Ejemplos: Processing Method, Color
- Verificar dimensionalidad resultante

**Label Encoding:**
- Considerar para variables ordinales si existen
- Documentar mapeo de etiquetas

**Frecuencia/Target Encoding (opcional):**
- Para variables con muchas categor√≠as (Country, Region)
- Evitar data leakage (aplicar solo en train)

#### 3. Escalado y Normalizaci√≥n

**Estandarizaci√≥n (StandardScaler):**
- Aplicar a variables num√©ricas para modelos sensibles a escala
- Guardar par√°metros (media, std) para aplicar en test

**Normalizaci√≥n Min-Max (opcional):**
- Considerar para redes neuronales
- Escalar entre [0,1] o [-1,1]

#### 4. Creaci√≥n de Features Derivadas (opcional)
- Ratios entre variables sensoriales
- Interacciones entre features importantes
- Features polin√≥micas si mejoran correlaci√≥n
- Agregaciones por pa√≠s/regi√≥n

#### 5. An√°lisis de Correlaci√≥n Detallado

**Matriz de Correlaci√≥n:**
- Calcular correlaci√≥n de Pearson entre todas las variables num√©ricas
- Crear heatmap con m√°scara triangular
- Identificar top correlaciones con variable objetivo
- Visualizar top 10 positivas y negativas

**An√°lisis de Multicolinealidad:**
- Identificar pares con |r| > 0.85
- Decidir qu√© variables eliminar o combinar
- Calcular VIF (Variance Inflation Factor) si es necesario

#### 6. An√°lisis Bivariado

**Variables Num√©ricas vs Target:**
- Scatter plots de top 5-8 correlaciones con Total Cup Score
- A√±adir l√≠neas de regresi√≥n lineal
- Calcular R¬≤ para cada relaci√≥n

**Variables Categ√≥ricas vs Target:**
- Boxplots/Violin plots por categor√≠a
- Ejemplos: Total Cup Score por Pa√≠s, por Processing Method
- Test ANOVA para diferencias significativas
- Post-hoc tests si ANOVA es significativo

#### 7. An√°lisis Multivariado

**Pairplot:**
- Crear pairplot de top 5-6 variables m√°s importantes
- Colorear por categor√≠a de calidad

**An√°lisis por Segmentos:**
- Segmentar datos por Quality Category (Exceptional, Excellent, Very Good)
- Comparar estad√≠sticas de features entre segmentos
- Identificar features que mejor discriminan calidad

#### 8. Feature Importance Preliminar

**Random Forest:**
- Entrenar Random Forest simple (no optimizado)
- Extraer importancia de Gini
- Visualizar top 15-20 features m√°s importantes
- Usar como gu√≠a para selecci√≥n de features

**Correlaci√≥n Absoluta:**
- Rankear features por |correlaci√≥n| con target
- Combinar con Random Forest importance

#### 9. Selecci√≥n de Features Finales
- Eliminar features redundantes (alta multicolinealidad)
- Eliminar features con correlaci√≥n muy baja (<0.05) con target
- Documentar features seleccionadas para modelado
- Crear lista final de features

#### 10. Guardar Datos Procesados
- Guardar dataset con features finales: `data/processed/coffee_features.csv`
- Guardar lista de features seleccionadas
- Guardar objetos de encoding/scaling (pickle/joblib)

### Entregables
- Dataset con features: `data/processed/coffee_features.csv`
- Lista de features seleccionadas
- Objetos de transformaci√≥n guardados
- Matriz de correlaci√≥n (figura)
- Top features por importancia (figura y tabla)

---

## ü§ñ 04_model_selection.ipynb

### Objetivo
Entrenar y comparar m√∫ltiples modelos de ML para identificar los mejores candidatos.

### Tareas Principales

#### 1. Preparaci√≥n de Datos

**Divisi√≥n de Datos:**
- Separar X (features) y y (target)
- Divisi√≥n estratificada: 70% train, 15% validation, 15% test
- O usar train-test split (70-30) + cross-validation
- Verificar distribuci√≥n de target en cada conjunto

**Pipeline de Preprocesamiento:**
- Crear ColumnTransformer para variables num√©ricas y categ√≥ricas
- Asegurar fit solo en train (evitar data leakage)

#### 2. Definici√≥n de Modelos Base

Entrenar al menos 5 modelos (requisito del proyecto):

**1. Modelo Param√©trico:**
- Linear Regression / Ridge / Lasso
- Explorar diferentes valores de alpha para regularizaci√≥n

**2. Modelo No Param√©trico:**
- K-Nearest Neighbors (KNN)
- Probar k = [3, 5, 7, 9, 11]
- Probar diferentes m√©tricas de distancia

**3. Modelo de Ensemble (√Årboles):**
- Random Forest Regressor
- Configuraci√≥n base: n_estimators=100, max_depth=10

**4. Red Neuronal:**
- Multi-Layer Perceptron (MLPRegressor)
- Arquitecturas: (64,), (128,64), (256,128,64)
- Activation: relu, tanh

**5. Support Vector Machine:**
- SVR con diferentes kernels: linear, rbf, poly
- Explorar valores de C y gamma

**Opcionales (recomendados):**
- XGBoost / LightGBM
- Gradient Boosting
- Elastic Net

#### 3. Configuraci√≥n Experimental

**Validaci√≥n Cruzada:**
- K-Fold Cross-Validation (k=5 o 10)
- Calcular media y desviaci√≥n est√°ndar de m√©tricas

**M√©tricas de Evaluaci√≥n:**
- MAE (Mean Absolute Error): error promedio absoluto
- RMSE (Root Mean Squared Error): penaliza errores grandes
- R¬≤ (R-squared): bondad de ajuste
- MAPE (opcional): error porcentual

#### 4. Entrenamiento de Modelos Base

Para cada modelo:
- Entrenar con configuraci√≥n base
- Evaluar en conjunto de validaci√≥n
- Registrar m√©tricas
- Calcular tiempo de entrenamiento
- Guardar predicciones

#### 5. Comparaci√≥n de Modelos

**Tabla Comparativa:**
- Crear tabla con todos los modelos y sus m√©tricas
- Incluir: MAE, RMSE, R¬≤, tiempo de entrenamiento
- Ordenar por mejor R¬≤ o MAE

**Visualizaciones:**
- Gr√°fico de barras: comparaci√≥n de R¬≤ entre modelos
- Gr√°fico de barras: comparaci√≥n de MAE entre modelos
- Scatter plot: MAE vs R¬≤ (trade-off)

#### 6. Curvas de Aprendizaje

Para top 2-3 modelos:
- Generar learning curves (train vs validation score)
- Analizar underfitting/overfitting
- Identificar si m√°s datos ayudar√≠an

#### 7. An√°lisis de Predicciones

**Predicci√≥n vs Real:**
- Scatter plot de valores predichos vs reales
- A√±adir l√≠nea diagonal perfecta (y=x)
- Calcular R¬≤ en el gr√°fico

**Distribuci√≥n de Errores:**
- Histograma de residuos (errores)
- Verificar normalidad de residuos
- Identificar patrones en errores

#### 8. Selecci√≥n de Modelos para Optimizaci√≥n
- Identificar top 2-3 modelos con mejor desempe√±o
- Documentar justificaci√≥n de selecci√≥n
- Considerar: precisi√≥n, tiempo de entrenamiento, interpretabilidad

### Entregables
- Tabla comparativa de modelos
- Gr√°ficos de comparaci√≥n de m√©tricas
- Learning curves de mejores modelos
- Identificaci√≥n de top 2-3 modelos para optimizar

---

## üìâ 05_dimensionality_reduction.ipynb

### Objetivo
Aplicar t√©cnicas de reducci√≥n de dimensionalidad (PCA y UMAP) y evaluar impacto en modelos.

### Tareas Principales

#### 1. Preparaci√≥n de Datos
- Cargar datos con todas las features
- Asegurar que datos est√©n escalados (cr√≠tico para PCA)
- Separar train/test

#### 2. An√°lisis de Componentes Principales (PCA)

**Varianza Explicada:**
- Aplicar PCA con todos los componentes
- Graficar varianza explicada por componente
- Graficar varianza explicada acumulada
- Identificar "codo" (elbow point)

**Criterios de Selecci√≥n:**
- Mantener componentes que expliquen ‚â•85-95% varianza
- O criterio del codo
- Documentar justificaci√≥n

**Aplicaci√≥n de PCA:**
- Transformar datos con n√∫mero seleccionado de componentes
- Calcular reducci√≥n de dimensionalidad (%)
- Ejemplo: 25 features ‚Üí 10 componentes (60% reducci√≥n)

**Interpretaci√≥n:**
- Analizar loadings de primeros 2-3 componentes
- Identificar qu√© features originales tienen mayor peso
- Visualizar en 2D/3D coloreando por Quality Category

#### 3. Aplicaci√≥n de UMAP

**Exploraci√≥n de Hiperpar√°metros:**
- n_neighbors: [5, 15, 30, 50]
- min_dist: [0.0, 0.1, 0.3, 0.5]
- n_components: [2, 3, 5, 10]
- metric: 'euclidean', 'manhattan', 'cosine'

**Selecci√≥n de Configuraci√≥n:**
- Probar diferentes combinaciones
- Visualizar embeddings 2D
- Seleccionar configuraci√≥n que preserve estructura
- Balance entre estructura local y global

**Aplicaci√≥n de UMAP:**
- Transformar con configuraci√≥n √≥ptima
- Visualizar en 2D/3D con colores por calidad
- Identificar clustering de categor√≠as

#### 4. Re-entrenamiento de Modelos

**Modelos a Re-entrenar:**
- Top 2 mejores modelos de fase de optimizaci√≥n
- Ejemplos: Random Forest optimizado, MLP optimizado

**Con PCA:**
- Entrenar cada modelo con datos reducidos por PCA
- Evaluar en validation/test set
- Calcular m√©tricas: MAE, RMSE, R¬≤

**Con UMAP:**
- Entrenar cada modelo con datos reducidos por UMAP
- Evaluar en validation/test set
- Calcular mismas m√©tricas

#### 5. Comparaci√≥n de Resultados

**Tabla Comparativa:**
| Modelo | Datos Originales | PCA | UMAP |
|--------|-----------------|-----|------|
| Random Forest | R¬≤=0.XX | R¬≤=0.YY | R¬≤=0.ZZ |
| MLP | R¬≤=0.XX | R¬≤=0.YY | R¬≤=0.ZZ |

Incluir: MAE, RMSE, R¬≤, % reducci√≥n dimensi√≥n, tiempo entrenamiento

**An√°lisis de Trade-off:**
- Reducci√≥n de dimensi√≥n vs p√©rdida de desempe√±o
- ¬øVale la pena reducir dimensiones?
- ¬øQu√© m√©todo (PCA/UMAP) funciona mejor?

#### 6. Visualizaciones Finales

**Scatter Plots 2D:**
- Datos reducidos a 2D (PCA y UMAP)
- Colorear por categor√≠a de calidad
- Identificar separabilidad de clases

**Importancia de Features (post-PCA):**
- Para Random Forest entrenado en componentes PCA
- Identificar componentes m√°s importantes

#### 7. Conclusiones sobre Reducci√≥n

- ¬øSe logr√≥ reducci√≥n significativa (>40%) sin p√©rdida de desempe√±o?
- ¬øQu√© t√©cnica funciona mejor: PCA o UMAP?
- ¬øRecomendaci√≥n final: usar datos originales o reducidos?
- Documentar ventajas/desventajas de reducci√≥n

### Entregables
- Gr√°ficos de varianza explicada (PCA)
- Visualizaciones 2D/3D de embeddings
- Modelos entrenados con datos reducidos
- Tabla comparativa completa
- Recomendaci√≥n final documentada

