# NOTEBOOKS_GUIDE.md

```markdown
# Gu√≠a de Notebooks para Proyecto de Predicci√≥n de Calidad del Caf√©

Esta gu√≠a describe el prop√≥sito, contenido y entregables de cada notebook en el proyecto.

---

## üìä 01_exploratory_data_analysis.ipynb

### Objetivo
Explorar y entender profundamente el dataset de calidad del caf√© del CQI antes de cualquier transformaci√≥n.

### Tareas Principales

#### 1. Configuraci√≥n Inicial
- Importar librer√≠as necesarias (pandas, numpy, matplotlib, seaborn, missingno)
- Configurar opciones de visualizaci√≥n y estilo de gr√°ficos
- Establecer semilla aleatoria para reproducibilidad

#### 2. Carga e Inspecci√≥n de Datos
- Cargar datasets de Arabica y Robusta desde `data/raw/`
- Mostrar informaci√≥n b√°sica: dimensiones, tipos de datos, primeras/√∫ltimas filas
- Listar todas las columnas y clasificarlas por tipo (num√©ricas, categ√≥ricas, target)

#### 3. An√°lisis de Calidad de Datos
- **Valores Faltantes:**
  - Calcular porcentaje de missing values por variable
  - Crear visualizaci√≥n con missingno (matriz y heatmap)
  - Identificar patrones de valores faltantes (MCAR, MAR, MNAR)
  - Clasificar variables: eliminar (>70% missing), imputar (<20%), analizar (20-70%)
- **Duplicados:**
  - Verificar registros duplicados completos
  - Mostrar ejemplos si existen
- **Consistencia:**
  - Verificar rangos v√°lidos (variables sensoriales 0-10, Total Cup Score 0-100)
  - Identificar valores fuera de rango esperado

#### 4. An√°lisis Univariado

**Variables Num√©ricas:**
- Calcular estad√≠sticas descriptivas completas (media, mediana, std, min, max, cuartiles)
- Calcular skewness y kurtosis para cada variable
- Interpretar distribuciones (sim√©trica, sesgada, colas pesadas)
- Crear histogramas + KDE para variables sensoriales
- Crear boxplots para detectar outliers
- An√°lisis detallado de variable objetivo (Total Cup Score):
  - Distribuci√≥n completa con m√∫ltiples visualizaciones
  - Clasificaci√≥n por categor√≠as CQI (Exceptional ‚â•90, Excellent 85-89, Very Good 80-84)
  - Q-Q plot para test de normalidad
  - Funci√≥n de distribuci√≥n acumulada

**Variables Categ√≥ricas:**
- Calcular n√∫mero de valores √∫nicos
- Mostrar top categor√≠as m√°s frecuentes
- Crear gr√°ficos de barras horizontales para top 10-15 categor√≠as
- Analizar: Country of Origin, Processing Method, Variety, Region

#### 5. An√°lisis de Outliers
- Detectar outliers usando m√©todo IQR (rango intercuart√≠lico)
- Detectar outliers usando Z-score (threshold=3)
- Calcular porcentaje de outliers por variable
- Crear tabla resumen de outliers
- Visualizar cantidad y porcentaje de outliers
- **Decisi√≥n preliminar:** Documentar qu√© hacer con outliers (mantener, transformar, eliminar)

#### 6. Conclusiones del EDA
- Resumen ejecutivo de hallazgos principales
- Insights clave sobre la calidad del caf√©
- Decisiones documentadas para preprocesamiento
- Variables candidatas a eliminar
- Estrategias de imputaci√≥n recomendadas

### Entregables
- Notebook completo con an√°lisis y visualizaciones
- Archivo `reports/EDA_Summary_Report.txt` con conclusiones
- ~10-15 visualizaciones guardadas en `reports/figures/eda/`

---

## üßπ 02_data_preprocessing.ipynb

### Objetivo
Limpiar y preparar los datos aplicando las decisiones tomadas durante el EDA.

### Tareas Principales

#### 1. Carga de Datos
- Cargar dataset original desde `data/raw/`
- Verificar integridad de los datos

#### 2. Limpieza de Datos

**Valores Faltantes:**
- Implementar estrategia de imputaci√≥n seg√∫n tipo de variable:
  - Variables num√©ricas: mediana (robusto ante outliers)
  - Variables categ√≥ricas: moda (valor m√°s frecuente)
  - Documentar cada decisi√≥n con justificaci√≥n
- Eliminar variables con >70% missing values
- Crear indicadores de imputaci√≥n si es necesario (flag columns)

**Duplicados:**
- Eliminar registros duplicados completos
- Documentar cu√°ntos se eliminaron

**Inconsistencias:**
- Corregir formatos de texto (min√∫sculas, eliminar espacios)
- Estandarizar nombres de categor√≠as (ej: "Washed" vs "washed" vs "WASHED")
- Convertir tipos de datos seg√∫n corresponda

#### 3. Tratamiento de Outliers
- Aplicar decisi√≥n tomada en EDA para cada variable:
  - Mantener: documentar justificaci√≥n (casos extremos leg√≠timos)
  - Transformar: aplicar log, sqrt, o winsorizing
  - Eliminar: solo si son errores claros de datos
- Registrar cu√°ntos outliers se trataron

#### 4. Eliminaci√≥n de Variables Irrelevantes
- Eliminar columnas identificadas en EDA:
  - Variables con >70% missing
  - Variables con varianza cero
  - Variables ID o redundantes
- Documentar raz√≥n de eliminaci√≥n

#### 5. Verificaci√≥n de Datos Limpios
- Verificar que no quedan valores faltantes (excepto estrat√©gicos)
- Verificar rangos de variables
- Calcular nuevas estad√≠sticas descriptivas
- Comparar antes vs despu√©s de limpieza

#### 6. Guardar Dataset Limpio
- Guardar en `data/processed/coffee_cleaned.csv`
- Guardar versiones separadas si es necesario (arabica_cleaned, robusta_cleaned)
- Crear diccionario de datos actualizado

### Entregables
- Dataset limpio: `data/processed/coffee_cleaned.csv`
- Resumen de transformaciones aplicadas
- Comparaci√≥n antes/despu√©s de limpieza

---

## üîß 03_feature_engineering.ipynb

### Objetivo
Crear nuevas caracter√≠sticas, codificar variables categ√≥ricas y preparar datos para modelado.

### Tareas Principales

#### 1. Carga de Datos Limpios
- Cargar `data/processed/coffee_cleaned.csv`
- Verificar integridad

#### 2. Codificaci√≥n de Variables Categ√≥ricas

**One-Hot Encoding:**
- Aplicar a variables con <20 categor√≠as √∫nicas
- Ejemplos: Processing Method, Color
- Verificar dimensionalidad resultante

**Label Encoding:**
- Considerar para variables ordinales si existen
- Documentar mapeo de etiquetas

**Frecuencia/Target Encoding (opcional):**
- Para variables con muchas categor√≠as (Country, Region)
- Evitar data leakage (aplicar solo en train)

#### 3. Escalado y Normalizaci√≥n

**Estandarizaci√≥n (StandardScaler):**
- Aplicar a variables num√©ricas para modelos sensibles a escala
- Guardar par√°metros (media, std) para aplicar en test

**Normalizaci√≥n Min-Max (opcional):**
- Considerar para redes neuronales
- Escalar entre [0,1] o [-1,1]

#### 4. Creaci√≥n de Features Derivadas (opcional)
- Ratios entre variables sensoriales
- Interacciones entre features importantes
- Features polin√≥micas si mejoran correlaci√≥n
- Agregaciones por pa√≠s/regi√≥n

#### 5. An√°lisis de Correlaci√≥n Detallado

**Matriz de Correlaci√≥n:**
- Calcular correlaci√≥n de Pearson entre todas las variables num√©ricas
- Crear heatmap con m√°scara triangular
- Identificar top correlaciones con variable objetivo
- Visualizar top 10 positivas y negativas

**An√°lisis de Multicolinealidad:**
- Identificar pares con |r| > 0.85
- Decidir qu√© variables eliminar o combinar
- Calcular VIF (Variance Inflation Factor) si es necesario

#### 6. An√°lisis Bivariado

**Variables Num√©ricas vs Target:**
- Scatter plots de top 5-8 correlaciones con Total Cup Score
- A√±adir l√≠neas de regresi√≥n lineal
- Calcular R¬≤ para cada relaci√≥n

**Variables Categ√≥ricas vs Target:**
- Boxplots/Violin plots por categor√≠a
- Ejemplos: Total Cup Score por Pa√≠s, por Processing Method
- Test ANOVA para diferencias significativas
- Post-hoc tests si ANOVA es significativo

#### 7. An√°lisis Multivariado

**Pairplot:**
- Crear pairplot de top 5-6 variables m√°s importantes
- Colorear por categor√≠a de calidad

**An√°lisis por Segmentos:**
- Segmentar datos por Quality Category (Exceptional, Excellent, Very Good)
- Comparar estad√≠sticas de features entre segmentos
- Identificar features que mejor discriminan calidad

#### 8. Feature Importance Preliminar

**Random Forest:**
- Entrenar Random Forest simple (no optimizado)
- Extraer importancia de Gini
- Visualizar top 15-20 features m√°s importantes
- Usar como gu√≠a para selecci√≥n de features

**Correlaci√≥n Absoluta:**
- Rankear features por |correlaci√≥n| con target
- Combinar con Random Forest importance

#### 9. Selecci√≥n de Features Finales
- Eliminar features redundantes (alta multicolinealidad)
- Eliminar features con correlaci√≥n muy baja (<0.05) con target
- Documentar features seleccionadas para modelado
- Crear lista final de features

#### 10. Guardar Datos Procesados
- Guardar dataset con features finales: `data/processed/coffee_features.csv`
- Guardar lista de features seleccionadas
- Guardar objetos de encoding/scaling (pickle/joblib)

### Entregables
- Dataset con features: `data/processed/coffee_features.csv`
- Lista de features seleccionadas
- Objetos de transformaci√≥n guardados
- Matriz de correlaci√≥n (figura)
- Top features por importancia (figura y tabla)

---

## ü§ñ 04_model_selection.ipynb

### Objetivo
Entrenar y comparar m√∫ltiples modelos de ML para identificar los mejores candidatos.

### Tareas Principales

#### 1. Preparaci√≥n de Datos

**Divisi√≥n de Datos:**
- Separar X (features) y y (target)
- Divisi√≥n estratificada: 70% train, 15% validation, 15% test
- O usar train-test split (70-30) + cross-validation
- Verificar distribuci√≥n de target en cada conjunto

**Pipeline de Preprocesamiento:**
- Crear ColumnTransformer para variables num√©ricas y categ√≥ricas
- Asegurar fit solo en train (evitar data leakage)

#### 2. Definici√≥n de Modelos Base

Entrenar al menos 5 modelos (requisito del proyecto):

**1. Modelo Param√©trico:**
- Linear Regression / Ridge / Lasso
- Explorar diferentes valores de alpha para regularizaci√≥n

**2. Modelo No Param√©trico:**
- K-Nearest Neighbors (KNN)
- Probar k = [3, 5, 7, 9, 11]
- Probar diferentes m√©tricas de distancia

**3. Modelo de Ensemble (√Årboles):**
- Random Forest Regressor
- Configuraci√≥n base: n_estimators=100, max_depth=10

**4. Red Neuronal:**
- Multi-Layer Perceptron (MLPRegressor)
- Arquitecturas: (64,), (128,64), (256,128,64)
- Activation: relu, tanh

**5. Support Vector Machine:**
- SVR con diferentes kernels: linear, rbf, poly
- Explorar valores de C y gamma

**Opcionales (recomendados):**
- XGBoost / LightGBM
- Gradient Boosting
- Elastic Net

#### 3. Configuraci√≥n Experimental

**Validaci√≥n Cruzada:**
- K-Fold Cross-Validation (k=5 o 10)
- Calcular media y desviaci√≥n est√°ndar de m√©tricas

**M√©tricas de Evaluaci√≥n:**
- MAE (Mean Absolute Error): error promedio absoluto
- RMSE (Root Mean Squared Error): penaliza errores grandes
- R¬≤ (R-squared): bondad de ajuste
- MAPE (opcional): error porcentual

#### 4. Entrenamiento de Modelos Base

Para cada modelo:
- Entrenar con configuraci√≥n base
- Evaluar en conjunto de validaci√≥n
- Registrar m√©tricas
- Calcular tiempo de entrenamiento
- Guardar predicciones

#### 5. Comparaci√≥n de Modelos

**Tabla Comparativa:**
- Crear tabla con todos los modelos y sus m√©tricas
- Incluir: MAE, RMSE, R¬≤, tiempo de entrenamiento
- Ordenar por mejor R¬≤ o MAE

**Visualizaciones:**
- Gr√°fico de barras: comparaci√≥n de R¬≤ entre modelos
- Gr√°fico de barras: comparaci√≥n de MAE entre modelos
- Scatter plot: MAE vs R¬≤ (trade-off)

#### 6. Curvas de Aprendizaje

Para top 2-3 modelos:
- Generar learning curves (train vs validation score)
- Analizar underfitting/overfitting
- Identificar si m√°s datos ayudar√≠an

#### 7. An√°lisis de Predicciones

**Predicci√≥n vs Real:**
- Scatter plot de valores predichos vs reales
- A√±adir l√≠nea diagonal perfecta (y=x)
- Calcular R¬≤ en el gr√°fico

**Distribuci√≥n de Errores:**
- Histograma de residuos (errores)
- Verificar normalidad de residuos
- Identificar patrones en errores

#### 8. Selecci√≥n de Modelos para Optimizaci√≥n
- Identificar top 2-3 modelos con mejor desempe√±o
- Documentar justificaci√≥n de selecci√≥n
- Considerar: precisi√≥n, tiempo de entrenamiento, interpretabilidad

### Entregables
- Tabla comparativa de modelos
- Gr√°ficos de comparaci√≥n de m√©tricas
- Learning curves de mejores modelos
- Identificaci√≥n de top 2-3 modelos para optimizar

---

## ‚öôÔ∏è 05_model_optimization.ipynb

### Objetivo
Optimizar hiperpar√°metros de los mejores modelos identificados en model selection.

### Tareas Principales

#### 1. Carga de Setup Experimental
- Cargar datos procesados
- Recrear split train/validation/test
- Cargar configuraci√≥n de mejores modelos

#### 2. Definici√≥n de Espacios de B√∫squeda

Para cada modelo seleccionado, definir grid de hiperpar√°metros:

**Random Forest:**
- n_estimators: [50, 100, 200, 500]
- max_depth: [5, 10, 15, 20, None]
- min_samples_split: [2, 5, 10]
- min_samples_leaf: [1, 2, 4]
- max_features: ['sqrt', 'log2', None]

**MLP (Red Neuronal):**
- hidden_layer_sizes: [(64,), (128,64), (256,128,64), (128,128)]
- activation: ['relu', 'tanh']
- learning_rate: [0.001, 0.01, 0.1]
- alpha (regularizaci√≥n): [0.0001, 0.001, 0.01]
- max_iter: [100, 200, 500]

**SVM:**
- kernel: ['linear', 'rbf', 'poly']
- C: [0.1, 1, 10, 100]
- gamma: [0.001, 0.01, 0.1, 1] (para rbf/poly)
- epsilon: [0.01, 0.1, 0.5]

#### 3. Optimizaci√≥n de Hiperpar√°metros

**GridSearchCV:**
- B√∫squeda exhaustiva en grid completo
- Cross-validation: 5-fold
- Scoring: 'neg_mean_absolute_error' o 'r2'
- n_jobs=-1 (usar todos los cores)

**RandomizedSearchCV (alternativa):**
- B√∫squeda aleatoria (m√°s r√°pida para grids grandes)
- n_iter: 50-100 iteraciones
- Mismo scoring y CV que GridSearch

#### 4. An√°lisis de Resultados de Optimizaci√≥n

Para cada modelo optimizado:
- Mostrar mejores hiperpar√°metros encontrados
- Comparar score de modelo base vs optimizado
- Crear tabla de top 5-10 configuraciones
- Visualizar efecto de hiperpar√°metros clave en desempe√±o

#### 5. Validaci√≥n de Modelos Optimizados

**Evaluaci√≥n en Validation Set:**
- Predecir con mejores modelos
- Calcular m√©tricas: MAE, RMSE, R¬≤
- Comparar con modelos base

**Curvas de Aprendizaje:**
- Generar learning curves para modelos optimizados
- Comparar con curvas de modelos base
- Verificar reducci√≥n de overfitting

#### 6. An√°lisis de Convergencia (MLP)

Para redes neuronales:
- Graficar loss curve durante entrenamiento
- Verificar convergencia
- Identificar si necesita m√°s epochs

#### 7. Entrenamiento Final

**Re-entrenar en Train + Validation:**
- Combinar train y validation sets
- Entrenar modelos optimizados en dataset combinado
- Guardar modelos finales en `models/`

**Persistencia:**
- Guardar modelos con joblib o pickle
- Nombrar claramente: `random_forest_optimized.pkl`
- Guardar tambi√©n hiperpar√°metros en JSON/YAML

#### 8. Comparaci√≥n Final

**Tabla Comparativa:**
- Modelo base vs optimizado para cada algoritmo
- Mejora porcentual en m√©tricas
- Tiempo de entrenamiento

**Mejores Modelos:**
- Identificar top 1-2 modelos generales
- Documentar configuraci√≥n final

### Entregables
- Modelos optimizados guardados en `models/`
- Tabla de mejores hiperpar√°metros
- Comparaci√≥n base vs optimizado
- Archivo de configuraci√≥n de hiperpar√°metros

---

## üìâ 06_dimensionality_reduction.ipynb

### Objetivo
Aplicar t√©cnicas de reducci√≥n de dimensionalidad (PCA y UMAP) y evaluar impacto en modelos.

### Tareas Principales

#### 1. Preparaci√≥n de Datos
- Cargar datos con todas las features
- Asegurar que datos est√©n escalados (cr√≠tico para PCA)
- Separar train/test

#### 2. An√°lisis de Componentes Principales (PCA)

**Varianza Explicada:**
- Aplicar PCA con todos los componentes
- Graficar varianza explicada por componente
- Graficar varianza explicada acumulada
- Identificar "codo" (elbow point)

**Criterios de Selecci√≥n:**
- Mantener componentes que expliquen ‚â•85-95% varianza
- O criterio del codo
- Documentar justificaci√≥n

**Aplicaci√≥n de PCA:**
- Transformar datos con n√∫mero seleccionado de componentes
- Calcular reducci√≥n de dimensionalidad (%)
- Ejemplo: 25 features ‚Üí 10 componentes (60% reducci√≥n)

**Interpretaci√≥n:**
- Analizar loadings de primeros 2-3 componentes
- Identificar qu√© features originales tienen mayor peso
- Visualizar en 2D/3D coloreando por Quality Category

#### 3. Aplicaci√≥n de UMAP

**Exploraci√≥n de Hiperpar√°metros:**
- n_neighbors: [5, 15, 30, 50]
- min_dist: [0.0, 0.1, 0.3, 0.5]
- n_components: [2, 3, 5, 10]
- metric: 'euclidean', 'manhattan', 'cosine'

**Selecci√≥n de Configuraci√≥n:**
- Probar diferentes combinaciones
- Visualizar embeddings 2D
- Seleccionar configuraci√≥n que preserve estructura
- Balance entre estructura local y global

**Aplicaci√≥n de UMAP:**
- Transformar con configuraci√≥n √≥ptima
- Visualizar en 2D/3D con colores por calidad
- Identificar clustering de categor√≠as

#### 4. Re-entrenamiento de Modelos

**Modelos a Re-entrenar:**
- Top 2 mejores modelos de fase de optimizaci√≥n
- Ejemplos: Random Forest optimizado, MLP optimizado

**Con PCA:**
- Entrenar cada modelo con datos reducidos por PCA
- Evaluar en validation/test set
- Calcular m√©tricas: MAE, RMSE, R¬≤

**Con UMAP:**
- Entrenar cada modelo con datos reducidos por UMAP
- Evaluar en validation/test set
- Calcular mismas m√©tricas

#### 5. Comparaci√≥n de Resultados

**Tabla Comparativa:**
| Modelo | Datos Originales | PCA | UMAP |
|--------|-----------------|-----|------|
| Random Forest | R¬≤=0.XX | R¬≤=0.YY | R¬≤=0.ZZ |
| MLP | R¬≤=0.XX | R¬≤=0.YY | R¬≤=0.ZZ |

Incluir: MAE, RMSE, R¬≤, % reducci√≥n dimensi√≥n, tiempo entrenamiento

**An√°lisis de Trade-off:**
- Reducci√≥n de dimensi√≥n vs p√©rdida de desempe√±o
- ¬øVale la pena reducir dimensiones?
- ¬øQu√© m√©todo (PCA/UMAP) funciona mejor?

#### 6. Visualizaciones Finales

**Scatter Plots 2D:**
- Datos reducidos a 2D (PCA y UMAP)
- Colorear por categor√≠a de calidad
- Identificar separabilidad de clases

**Importancia de Features (post-PCA):**
- Para Random Forest entrenado en componentes PCA
- Identificar componentes m√°s importantes

#### 7. Conclusiones sobre Reducci√≥n

- ¬øSe logr√≥ reducci√≥n significativa (>40%) sin p√©rdida de desempe√±o?
- ¬øQu√© t√©cnica funciona mejor: PCA o UMAP?
- ¬øRecomendaci√≥n final: usar datos originales o reducidos?
- Documentar ventajas/desventajas de reducci√≥n

### Entregables
- Gr√°ficos de varianza explicada (PCA)
- Visualizaciones 2D/3D de embeddings
- Modelos entrenados con datos reducidos
- Tabla comparativa completa
- Recomendaci√≥n final documentada

---

## üìä 07_final_results.ipynb

### Objetivo
Consolidar y presentar resultados finales del proyecto, comparar con estado del arte.

### Tareas Principales

#### 1. Resumen del Proyecto
- Descripci√≥n breve del problema
- Objetivos del proyecto
- Dataset utilizado (caracter√≠sticas principales)
- Metodolog√≠a seguida

#### 2. Carga de Resultados

**Modelos Entrenados:**
- Cargar todos los modelos guardados
- Cargar resultados de experimentos anteriores

**Datos de Test:**
- Cargar conjunto de test no visto
- Verificar que no se us√≥ durante entrenamiento/validaci√≥n

#### 3. Evaluaci√≥n Final en Test Set

Para cada modelo final:
- Generar predicciones en test set
- Calcular m√©tricas: MAE, RMSE, R¬≤, MAPE
- Calcular intervalos de confianza (bootstrap si es posible)

#### 4. Tabla Resumen de Todos los Experimentos

**Estructura de Tabla:**
| Experimento | Modelo | Features | MAE | RMSE | R¬≤ | Notas |
|-------------|--------|----------|-----|------|----|-------|
| Baseline | Linear Reg | Todas | X.XX | X.XX | 0.XX | - |
| Base | Random Forest | Todas | X.XX | X.XX | 0.XX | - |
| Optimizado | RF Optimized | Todas | X.XX | X.XX | 0.XX | Grid Search |
| PCA | RF Optimized | 10 PCA | X.XX | X.XX | 0.XX | 60% reducci√≥n |
| UMAP | RF Optimized | 5 UMAP | X.XX | X.XX | 0.XX | n_neighbors=15 |

Ordenar por R¬≤ o MAE

#### 5. Visualizaciones de Resultados

**Predicci√≥n vs Real:**
- Scatter plot del mejor modelo
- A√±adir l√≠nea diagonal y de regresi√≥n
- Colorear puntos por categor√≠a de calidad
- Mostrar R¬≤ y MAE en el gr√°fico

**An√°lisis de Residuos:**
- Gr√°fico de residuos vs valores predichos
- Histograma de residuos (verificar normalidad)
- Q-Q plot de residuos

**Feature Importance Final:**
- Del mejor modelo (Random Forest o XGBoost)
- Top 15-20 features m√°s importantes
- Gr√°fico de barras horizontal

**Comparaci√≥n de Modelos:**
- Gr√°fico de barras: R¬≤ de todos los modelos
- Gr√°fico de barras: MAE de todos los modelos
- Gr√°fico de radar: m√∫ltiples m√©tricas

#### 6. An√°lisis de Errores

**Casos con Mayor Error:**
- Identificar 10-20 predicciones con mayor error absoluto
- Analizar caracter√≠sticas de estos casos
- ¬øHay patrones? (pa√≠s, m√©todo procesamiento, etc.)

**Distribuci√≥n de Errores por Categor√≠a:**
- Calcular MAE por categor√≠a de calidad
- ¬øEl modelo predice mejor ciertos rangos de calidad?

#### 7. Comparaci√≥n con Estado del Arte

**Art√≠culos Revisados:**
Recordar los art√≠culos que revisaste:
1. "Coffee Quality Prediction" (2024): Random Forest R¬≤=0.82, MAE=0.16
2. "LGBM Algorithm" (2023): Accuracy 72% (clasificaci√≥n)
3. "UBC-MDS" (2021): ROC-AUC=0.67 (clasificaci√≥n)
4. "ML Techniques" (2023): SVR mejor desempe√±o

**Tabla Comparativa:**
| Fuente | M√©todo | M√©trica | Resultado |
|--------|--------|---------|-----------|
| Art√≠culo 1 | Random Forest | R¬≤ | 0.82 |
| Art√≠culo 1 | Random Forest | MAE | 0.16 |
| **Tu Trabajo** | **Random Forest Opt** | **R¬≤** | **0.XX** |
| **Tu Trabajo** | **Random Forest Opt** | **MAE** | **0.XX** |

**An√°lisis:**
- ¬øSuperaste los resultados del estado del arte?
- Si s√≠: ¬øPor qu√©? (m√°s features, mejor optimizaci√≥n, etc.)
- Si no: ¬øPor qu√©? (menos datos, diferentes features, etc.)

#### 8. Insights y Descubrimientos Clave

**Features M√°s Importantes:**
- Top 5 features que m√°s influyen en calidad
- Coherencia con conocimiento del dominio (caf√©)

**Hallazgos Interesantes:**
- Relaciones inesperadas descubiertas
- Patrones en datos
- Diferencias por pa√≠s/m√©todo de procesamiento

#### 9. Limitaciones del Estudio

**Limitaciones de Datos:**
- Dataset de 2018 (no captura variaciones recientes)
- Desbalance Arabica (1312) vs Robusta (28)
- Posible sesgo geogr√°fico

**Limitaciones Metodol√≥gicas:**
- Supuestos de modelos
- Variables no capturadas (microclima, pr√°cticas espec√≠ficas)
- Validaci√≥n limitada a datos hist√≥ricos

#### 10. Recomendaciones y Trabajo Futuro

**Para Mejorar Modelos:**
- Incorporar m√°s datos recientes
- Incluir features de clima/suelo
- Probar deep learning (LSTM, Transformers)
- Ensemble de m√∫ltiples modelos

**Aplicaciones Pr√°cticas:**
- Sistema de predicci√≥n para productores peque√±os
- Herramienta de verificaci√≥n de precios
- App m√≥vil para evaluaci√≥n r√°pida

#### 11. Conclusiones Finales

**Resumen de Logros:**
- Modelo final alcanz√≥ R¬≤=0.XX y MAE=0.XX
- Reducci√≥n de dimensi√≥n logr√≥ X% sin p√©rdida significativa
- Sistema puede predecir calidad con X% de precisi√≥n

**Valor del Proyecto:**
- Democratiza evaluaci√≥n de calidad
- Reduce costos de certificaci√≥n
- Potencial de impacto en cadena de valor

**Reflexi√≥n Final:**
- Aprendizajes clave del proyecto
- Habilidades desarrolladas

### Entregables
- Notebook completo con todos los resultados
- Todas las visualizaciones finales
- Tabla comparativa completa
- Secci√≥n de conclusiones documentada
- Exportar resultados a `reports/final_report.pdf` (opcional)

---

## üìù Buenas Pr√°cticas Generales para Todos los Notebooks

### Estructura de Cada Notebook

1. **T√≠tulo y Metadata**
   - N√∫mero y nombre del notebook
   - Descripci√≥n breve del objetivo
   - Autor y fecha

2. **Tabla de Contenidos**
   - Para notebooks largos (>100 celdas)
   - Links clickeables a secciones

3. **Setup y Configuraci√≥n**
   - Imports organizados por categor√≠a
   - Configuraci√≥n de visualizaci√≥n
   - Semillas aleatorias para reproducibilidad

4. **Desarrollo Secuencial**
   - Secciones con headers Markdown (##, ###)
   - C√≥digo comentado
   - Interpretaci√≥n despu√©s de cada resultado
   - Visualizaciones con t√≠tulos y labels claros

5. **Conclusiones**
   - Resumen de hallazgos al final
   - Decisiones documentadas
   - Siguiente pasos

### Estilo de C√≥digo

```
# ‚úÖ BUENO
# Calculate correlation matrix for sensory variables
sensory_vars = ['Aroma', 'Flavor', 'Aftertaste']
corr_matrix = df[sensory_vars].corr()

# ‚ùå MALO (sin comentarios, nombres cr√≠pticos)
sv = ['Aroma', 'Flavor', 'Aftertaste']
cm = df[sv].corr()
```

### Visualizaciones

- Siempre incluir t√≠tulos descriptivos
- Labels en ejes X e Y
- Leyendas cuando sea necesario
- Tama√±o de fuente legible (12-14pt)
- Guardar figuras importantes en alta resoluci√≥n (300 dpi)

### Documentaci√≥n

- Explicar **qu√©** haces y **por qu√©**
- Interpretar resultados num√©ricos
- Documentar decisiones importantes
- A√±adir referencias a literatura cuando sea relevante

---

## ‚úÖ Checklist de Completitud

Antes de finalizar cada notebook, verificar:

- [ ] Todas las celdas ejecutan sin errores
- [ ] Resultados son reproducibles (semillas fijas)
- [ ] C√≥digo est√° comentado adecuadamente
- [ ] Visualizaciones tienen t√≠tulos y labels
- [ ] Conclusiones est√°n documentadas
- [ ] Se guardaron outputs necesarios (datos, modelos, figuras)
- [ ] Notebook est√° limpio (eliminar experimentos fallidos)
- [ ] Markdown est√° bien formateado
- [ ] Paths de archivos son relativos (no absolutos)

---

## üìö Referencias

- Gu√≠a del Proyecto: `Guia_proyecto_Modelos_II.pdf`
- Dataset: https://www.kaggle.com/datasets/volpatto/coffee-quality-database-from-cqi
- Art√≠culos del Estado del Arte (ver carpeta `references/`)

---

**√öltima actualizaci√≥n**: 2025-10-23
**Versi√≥n**: 1.0
```

***

Este archivo `.md` te servir√° como gu√≠a completa para desarrollar cada notebook del proyecto de manera profesional, organizada y cumpliendo con todos los requisitos del curso. Gu√°rdalo en la ra√≠z de tu repositorio para que t√∫ y cualquier colaborador sepan exactamente qu√© hacer en cada etapa.

[1](https://github.com/kylebradbury/ml-project-structure-demo)
[2](https://www.reddit.com/r/MachineLearning/comments/g8h58c/d_how_do_you_structure_and_organize_your_mldl/)
[3](https://www.kaggle.com/general/4815)
[4](https://app.readytensor.ai/publications/markdown-for-machine-learning-projects-a-comprehensive-guide-LX9cbIx7mQs9)
[5](https://github.com/onesamblack/machine-learning-template/blob/main/README.md)
[6](https://domino.ai/blog/the-importance-of-structure-coding-style-and-refactoring-in-notebooks)
[7](https://dev.to/luxdevhq/generic-folder-structure-for-your-machine-learning-projects-4coe)
[8](https://github.com/ZenithClown/ai-ml-project-template)
[9](https://towardsdatascience.com/its-time-to-structure-your-data-science-project-1fa064fbe46/)
[10](https://www.overleaf.com/latex/templates)